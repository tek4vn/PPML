{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HE_PATE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNjjlHtFhbQZVOvV0WMiMho",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tek4vn/PPML/blob/main/HE_PATE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHDblaPLJfmj"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6kKvzcLJduB"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        " \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        " \n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A609Tiv6JlCa"
      },
      "source": [
        "def polyfitX(x):\n",
        "    return 0.1524*(x**2) + 0.5*x + 0.409\n",
        " \n",
        "def polyfit(x):\n",
        "    return x**2\n",
        " \n",
        "\n",
        "class Polyfit(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "    def forward(self, input):\n",
        "        return polyfitX(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z5MWeD9JlyX"
      },
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_name):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Linear(512, 10)\n",
        " \n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        " \n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 1\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                # Dùng AvgPool thay MaxPool khi dùng hàm xấp xỉ thay ReLU\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "                \n",
        "                # layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "#                            Polyfit()]\n",
        "                            nn.ReLU(inplace=True)]\n",
        "                # layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                # nn.BatchNorm2d(x),\n",
        "                # nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
        "        return nn.Sequential(*layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpE_nCVNJnTn"
      },
      "source": [
        "class VGG_HE(nn.Module):\n",
        "    def __init__(self, vgg_name):\n",
        "        super(VGG_HE, self).__init__()\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Linear(512, 10)\n",
        " \n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        " \n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 1\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                # Dùng AvgPool thay MaxPool khi dùng hàm xấp xỉ thay ReLU\n",
        "                layers += [nn.AvgPool2d(kernel_size=2, stride=2)]\n",
        "                \n",
        "                # layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           Polyfit()]\n",
        "#                             nn.ReLU(inplace=True)]\n",
        "                # layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                # nn.BatchNorm2d(x),\n",
        "                # nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
        "        return nn.Sequential(*layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0n8uKGiJpgO"
      },
      "source": [
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta7U4qHxJrYq"
      },
      "source": [
        "transform_test = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVX1uQw2JuI9"
      },
      "source": [
        "trainset = torchvision.datasets.MNIST(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "#trainloader_mnist = torch.utils.data.DataLoader(\n",
        "#    trainset, batch_size=128, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzQ2DWICJv3X"
      },
      "source": [
        "testset = torchvision.datasets.MNIST(\n",
        "    root='./test', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXJSBiyNJ8WC"
      },
      "source": [
        "if torch.cuda.is_available():  \n",
        "    dev = \"cuda:0\" \n",
        "else:  \n",
        "    dev = \"cpu\"  \n",
        "device = torch.device(dev)\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcJ44qUoJxdy"
      },
      "source": [
        "cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51PH-diAJ415"
      },
      "source": [
        "X1, X2, student = torch.utils.data.random_split(trainset, [25000, 25000, 10000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qleb8t_9KZVZ"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u1SDcZwJ6vc"
      },
      "source": [
        "trainloaderX1 = torch.utils.data.DataLoader(\n",
        "    X1, batch_size=100, shuffle=True, num_workers=2)\n",
        "trainloaderX2 = torch.utils.data.DataLoader(\n",
        "    X2, batch_size=100, shuffle=True, num_workers=2)\n",
        "# trainloaderX3 = torch.utils.data.DataLoader(\n",
        "#     X3, batch_size=100, shuffle=True, num_workers=2)\n",
        "# trainloaderX4 = torch.utils.data.DataLoader(\n",
        "#     X4, batch_size=100, shuffle=True, num_workers=2)\n",
        "# trainloaderX5 = torch.utils.data.DataLoader(\n",
        "#     X5, batch_size=100, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDIJ0EotKA08"
      },
      "source": [
        "print('==> Building model..')\n",
        "net = VGG('VGG13')\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvn4GSu5KCg_"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, \n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgWMuszaKEgG"
      },
      "source": [
        "def train(epochs, dataload, model):\n",
        "    \n",
        "    for epoch in range(0, epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        print(\"Epoch\",epoch)\n",
        "        for batch_idx , (inputs, targets) in enumerate(dataload):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "        print('\\tLoss: '+ str(train_loss/(batch_idx+1)),\n",
        "              '\\tAccuracy: '+ str(100. * (correct/total)),\n",
        "              \"\\tCorrect/total: {correct}/{total}\".format(correct=correct, total=total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdBQeBOxKItL"
      },
      "source": [
        "train(15, trainloaderX1, net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KKrDX2DKMFd"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, \n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht9fKHFyKggj"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RJaStEHKiBq"
      },
      "source": [
        "def test(model, testload):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testload):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "        print(\"\\nTest set: Avg. loss: {}\\tAccuracy: {} \\tCorrect/Total: {}/{}\".format(\n",
        "                test_loss/(batch_idx+1), 100. * correct/total,\n",
        "                correct, total))\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaUPn3-RKoG3"
      },
      "source": [
        "test(net, testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov5JzzjWKsqf"
      },
      "source": [
        "# Student"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9AsnMgdKtwQ"
      },
      "source": [
        "from scipy import stats as s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPc2yATqK0f2"
      },
      "source": [
        "rd = torch.randint(0, 10000, (500,))\n",
        "st500 = torch.utils.data.Subset(student, rd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAnL75NKK2L-"
      },
      "source": [
        "rd = torch.randint(0, 10000, (1000,))\n",
        "st1k = torch.utils.data.Subset(student, rd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbGM5KPUK30y"
      },
      "source": [
        "rd = torch.randint(0, 10000, (2000,))\n",
        "st2k = torch.utils.data.Subset(student, rd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FykSuv7K5ka"
      },
      "source": [
        "rd = torch.randint(0, 10000, (5000,))\n",
        "st5k = torch.utils.data.Subset(student, rd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tWUa3NBK7kU"
      },
      "source": [
        "rd = torch.randint(0, 10000, (7500,))\n",
        "st7k5 = torch.utils.data.Subset(student, rd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7unIYypK8Sr"
      },
      "source": [
        "lstData = [st500, st1k, st2k, st5k, st7k5, student]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiXCbbd8K8bJ"
      },
      "source": [
        "stloader_500 = torch.utils.data.DataLoader(\n",
        "    st500, shuffle=False, num_workers=2)\n",
        "stloader_1k = torch.utils.data.DataLoader(\n",
        "    st1k, shuffle=False, num_workers=2)\n",
        "stloader_2k = torch.utils.data.DataLoader(\n",
        "    st2k, shuffle=False, num_workers=2)\n",
        "stloader_5k = torch.utils.data.DataLoader(\n",
        "    st5k, shuffle=False, num_workers=2)\n",
        "stloader_7k5 = torch.utils.data.DataLoader(\n",
        "    st7k5, shuffle=False, num_workers=2)\n",
        "stloader = torch.utils.data.DataLoader(\n",
        "    student, shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmvwf5h4LCeb"
      },
      "source": [
        "def pred(model1, model2, data):\n",
        "    model1.eval()\n",
        "    model2.eval()\n",
        "#     model3.eval()\n",
        "#     model4.eval()\n",
        "#     model5.eval()\n",
        "    predict_Mode = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in data:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            lb1, lb2 = model1(data).argmax().item(), model2(data).argmax().item()\n",
        "#             lb3 = model3(data).argmax().item()\n",
        "#             lb4 = model4(data).argmax().item()\n",
        "#             lb5 = model5(data).argmax().item()\n",
        "            Modelb = s.mode([lb1, lb2]).mode\n",
        "            predict_Mode.append([int(Modelb), target.item()])\n",
        "    return predict_Mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBqaKbkOLFTh"
      },
      "source": [
        "lstTest = []\n",
        "dict_data = {}\n",
        "nameLoader = ['st500', 'st1k', 'st2k', 'st5k', 'st7k5', 'student']\n",
        "lstLoader = [stloader_500, stloader_1k, stloader_2k, stloader_5k, stloader_7k5, stloader]\n",
        "for d in lstLoader:\n",
        "    label_test = pred(model1, model2, d )\n",
        "    ptram = 0\n",
        "    data_st = []\n",
        "    pred_Test = []\n",
        "    for i in range(len(label_test)):\n",
        "        pred_Test.append(label_test[i][0])\n",
        "        data_st.append([lstData[lstLoader.index(d)][i][0], label_test[i][0]])\n",
        "        if label_test[i][0] == label_test[i][1]:\n",
        "            ptram += 1\n",
        "    dict_data[nameLoader[lstLoader.index(d)]] = data_st\n",
        "    lstTest.append(ptram/len(label_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY7WvI5LLHok"
      },
      "source": [
        "dict_data['pred_Teacher'] = lstTest\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OCugN8PLSSB"
      },
      "source": [
        "def pred_st(data_, he=False):\n",
        "    __doc__ = \"\"\"Lấy data và tạo model\"\"\"\n",
        "    trainloader_st = torch.utils.data.DataLoader(\n",
        "            dict_data[data_], batch_size=100, shuffle=True, num_workers=2)\n",
        "    \n",
        "    if he:\n",
        "        print('==> Building model HE...')\n",
        "        net = VGG_HE('VGG11')\n",
        "        net = net.to(device)\n",
        "        if device == 'cuda':\n",
        "            net = torch.nn.DataParallel(net)\n",
        "            cudnn.benchmark = True\n",
        "        return net, trainloader_st\n",
        "    else:\n",
        "        print('==> Building model..')\n",
        "        net = VGG('VGG11')\n",
        "        net = net.to(device)\n",
        "        if device == 'cuda':\n",
        "            net = torch.nn.DataParallel(net)\n",
        "            cudnn.benchmark = True\n",
        "        return net, trainloader_st"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGL_PK4QLiHQ"
      },
      "source": [
        "net, trainloader_st = pred_st('student', False)\n",
        "# net, trainloader_st = pred_st('st500', True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLd3f9OuLpC4"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, \n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w7CXvemLqt2"
      },
      "source": [
        "train(25, trainloader_st, net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5-AevGRLrPd"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, \n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNNg4aIALtqg"
      },
      "source": [
        "train(25, trainloader_st, net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a9Y54i4L5Yf"
      },
      "source": [
        "accSt = test(net, testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hEzFDRGL8sS"
      },
      "source": [
        "# Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTomRBpFL9KP"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpGNeHxOMCcx"
      },
      "source": [
        "dict2 = torch.load('../input/dict-data/model2_teacher.data')\n",
        "dict3 = torch.load('../input/dictdata/model3_dictData.data')\n",
        "dict4 = torch.load('../input/dictdata/model4_dictData.data')\n",
        "dict5 = torch.load('../input/dictdata/model5_dictData.data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYXv2XqsMEH3"
      },
      "source": [
        "dict2_HE = torch.load('../input/dictdata/model2_HE.data')\n",
        "dict3_HE = torch.load('../input/dictdata/model3_HE.data')\n",
        "dict4_HE = torch.load('../input/dictdata/model4_HE.data')\n",
        "dict5_HE = torch.load('../input/dictdata/model5_HE.data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT14VoAsMHR4"
      },
      "source": [
        "xlabel = [500, 1000, 2000, 5000, 7500, 10000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26KHHMr9MMMP"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(2,figsize=(18, 13))\n",
        "fig.suptitle('Prediction vote', fontsize = 16)\n",
        "\n",
        "ax2.plot(xlabel, dict2['pred_Teacher'], marker='o')\n",
        "ax2.plot(xlabel, dict3['pred_Teacher'], marker='P')\n",
        "ax2.plot(xlabel, dict4['pred_Teacher'], marker='v')\n",
        "ax2.plot(xlabel, dict5['pred_Teacher'], marker='s')\n",
        "ax2.set_ylabel('Not use HE', fontsize=14)\n",
        "ax2.set_ylim(97, 100)\n",
        "ax2.set_xticks(xlabel)\n",
        "\n",
        "ax1.plot(xlabel, dict2_HE['pred_Teacher'], marker='o', label = '2 Teacher')\n",
        "ax1.plot(xlabel, dict3_HE['pred_Teacher'], marker='P', label = '3 Teacher')\n",
        "ax1.plot(xlabel, dict4_HE['pred_Teacher'], marker='v', label = '4 Teacher')\n",
        "ax1.plot(xlabel, dict5_HE['pred_Teacher'], marker='s', label = '5 Teacher')\n",
        "ax1.set_ylabel('Use HE', fontsize=14)\n",
        "ax1.set_ylim(97, 100)\n",
        "ax1.set_xticks(xlabel)\n",
        "ax1.legend(loc = \"lower right\")\n",
        "\n",
        "\n",
        "plt.xlabel('Samples', fontsize=16)\n",
        "fig.savefig('Case_vote.jpg')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeK7mZKEMNAm"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(2,figsize=(18, 13))\n",
        "fig.suptitle(\"Student's prediction\", fontsize = 16)\n",
        "\n",
        "ax1.plot(xlabel, dict2['pred_Student_HE'], marker='o', label = '2 Teacher')\n",
        "ax1.plot(xlabel, dict3['pred_Student_HE'], marker='P', label = '3 Teacher')\n",
        "ax1.plot(xlabel, dict4['pred_Student_HE'], marker='v', label = '4 Teacher')\n",
        "ax1.plot(xlabel, dict5['pred_Student_HE'], marker='s', label = '5 Teacher')\n",
        "ax1.set_ylabel('Use HE', fontsize=14)\n",
        "ax1.set_ylim(70, 100)\n",
        "ax1.set_xticks(xlabel)\n",
        "ax1.legend(loc = \"lower right\")\n",
        "\n",
        "ax2.plot(xlabel, dict2['pred_Student'], marker='o')\n",
        "ax2.plot(xlabel, dict3['pred_Student'], marker='P')\n",
        "ax2.plot(xlabel, dict4['pred_Student'], marker='v')\n",
        "ax2.plot(xlabel, dict5['pred_Student'], marker='s')\n",
        "ax2.set_ylabel('Not use HE', fontsize=14)\n",
        "ax2.set_ylim(70, 100)\n",
        "ax2.set_xticks(xlabel)\n",
        "\n",
        "\n",
        "\n",
        "plt.xlabel('Model', fontsize=16)\n",
        "fig.savefig('Case_student_Model.jpg')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}